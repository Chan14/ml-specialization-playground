{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0900b481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.datasets import make_blobs\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import cm\n",
    "import math\n",
    "np.set_printoptions(precision=2)\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d375ca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "keras.utils.set_random_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd747aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 4\n",
    "m = 100\n",
    "centers = [[-5, 2], [-2, -2], [1, 2], [5, -2]]\n",
    "std = 1.0\n",
    "X_train, y_train = make_blobs(\n",
    "    n_samples=m, centers=centers, cluster_std=std, random_state=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ecce9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hide_header_footer_toolbar(canvas):\n",
    "    canvas.header_visible = False\n",
    "    canvas.footer_visible = False\n",
    "    canvas.toolbar_visible = False\n",
    "\n",
    "\n",
    "def plt_mc_data(\n",
    "    ax,\n",
    "    X,\n",
    "    y,\n",
    "    classes,\n",
    "    class_labels=None,\n",
    "    cmap=\"tab10\",\n",
    "    legend=False,\n",
    "    size=50,\n",
    "    m=\"o\",\n",
    "    equal_xy=False,\n",
    "):\n",
    "    for i in range(classes):\n",
    "        idx = np.where(y == i)\n",
    "        col = len(idx[0]) * [i]\n",
    "        label = class_labels[i] if class_labels else \"c{}\".format(i)\n",
    "        cmap = plt.get_cmap(cmap)\n",
    "        ax.scatter(\n",
    "            X[idx, 0],\n",
    "            X[idx, 1],\n",
    "            c=col,\n",
    "            marker=m,\n",
    "            cmap=cmap,\n",
    "            vmin=0,\n",
    "            vmax=cmap.N,\n",
    "            s=size,\n",
    "            label=label,\n",
    "        )\n",
    "    if legend:\n",
    "        ax.legend()\n",
    "    if equal_xy:\n",
    "        ax.axis(\"equal\")\n",
    "\n",
    "\n",
    "def plt_mc(X_train, y_train, classes, centers, std):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "    hide_header_footer_toolbar(fig.canvas)\n",
    "    plt_mc_data(\n",
    "        ax,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        classes,\n",
    "        cmap=\"tab10\",\n",
    "        legend=True,\n",
    "        size=50,\n",
    "        equal_xy=False,\n",
    "    )\n",
    "    ax.set_title(\"Multiclass Data\")\n",
    "    ax.set_xlabel(\"x0\")\n",
    "    ax.set_ylabel(\"x1\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f328e6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_mc(X_train, y_train, classes, centers, std=std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6239b494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show classes in data set\n",
    "print(f\"Unique classes : {np.unique(y_train)}\")\n",
    "# show how classes are represented\n",
    "print(f\"Class representation : {y_train[:10]}\")\n",
    "# show shapes of our dataset\n",
    "print(f\"Shape of X_train : {X_train.shape}, Shape of y_train : {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72f244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [Dense(2, activation=\"relu\", name=\"L1\"), Dense(4, activation=\"linear\", name=\"L2\")]\n",
    ")\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(0.01),\n",
    ")\n",
    "model.fit(X_train, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a4697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_cat_decision_boundary_mc(ax, X, fn_pred, class_labels=None, legend=False):\n",
    "    X0_min, X0_max = np.min(X[:, 0]) - 0.5, np.max(X[:, 0]) + 0.5\n",
    "    X1_min, X1_max = np.min(X[:, 1]) - 0.5, np.max(X[:, 1]) + 0.5\n",
    "    h = max(X0_max - X0_min, X1_max - X1_min) / 100\n",
    "    X0, X1 = np.meshgrid(np.arange(X0_min, X0_max, h), np.arange(X1_min, X1_max, h))\n",
    "    points = np.c_[X0.ravel(), X1.ravel()]\n",
    "    Z = fn_pred(points)\n",
    "    Z = Z.reshape(X0.shape)\n",
    "    ax.contour(X0, X1, Z, lw=1)\n",
    "\n",
    "\n",
    "def plt_cat_mc(X, y, model, classes):\n",
    "    model_predict = lambda x: np.argmax(model.predict(x), axis=1)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "    hide_header_footer_toolbar(fig.canvas)\n",
    "    plt_mc_data(ax, X, y, classes, cmap=\"tab10\", legend=True)\n",
    "    plt_cat_decision_boundary_mc(ax, X, model_predict)\n",
    "    ax.set_title(\"Model Decision Boundary\")\n",
    "    plt.xlabel(r\"$x_0$\")\n",
    "    plt.ylabel(r\"$x_1$\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42354270",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_cat_mc(X_train, y_train, model, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ed677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather the trained parameters from the first layer\n",
    "W1, b1 = model.get_layer(\"L1\").get_weights()\n",
    "print(W1, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7186ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_prob_z(ax, fn, x0_rng=(-8, 8), x1_rng=(-5, 4)):\n",
    "    \"\"\"plots a decision boundary but include shading to indicate the probability\n",
    "    and adds a conouter to show where z=0\n",
    "    \"\"\"\n",
    "    x0_space, x1_space = np.linspace(*x0_rng, 40), np.linspace(*x1_rng, 40)\n",
    "    x0, x1 = np.meshgrid(x0_space, x1_space)\n",
    "    grid_points = np.c_[x0.ravel(), x1.ravel()]\n",
    "    z = fn(grid_points)\n",
    "    z = z.reshape(x0.shape)\n",
    "    c = np.where(z == 0, 0, 1)\n",
    "    ax.contour(x0, x1, c, linewidths=1)\n",
    "    cmap = ListedColormap(plt.get_cmap(\"Blues\")(np.linspace(0.0, 0.9, 256)))\n",
    "    pcm = ax.pcolormesh(\n",
    "        x0,\n",
    "        x1,\n",
    "        z,\n",
    "        norm=cm.colors.Normalize(vmin=np.amin(z), vmax=np.amax(z)),\n",
    "        cmap=cmap,\n",
    "        shading=\"nearest\",\n",
    "        alpha=0.9,\n",
    "    )\n",
    "    ax.figure.colorbar(pcm, ax=ax)\n",
    "\n",
    "\n",
    "def plt_layer_relu(X, Y, W, b, classes):\n",
    "    nunits = W.shape[1]\n",
    "    Y = Y.reshape(\n",
    "        -1,\n",
    "    )\n",
    "    fig, ax = plt.subplots(1, nunits, figsize=(7, 3))\n",
    "    hide_header_footer_toolbar(fig.canvas)\n",
    "\n",
    "    for i in range(nunits):\n",
    "        layer_fn = lambda x: np.maximum(0, np.dot(x, W[:, i]) + b[i])\n",
    "        plt_prob_z(ax[i], layer_fn)\n",
    "        plt_mc_data(ax[i], X, Y, classes, cmap=\"tab10\", legend=True, size=50, m=\"o\")\n",
    "        ax[i].set_title(f\"Unit {i}\")\n",
    "        ax[i].set_ylabel(r\"$x_1$\", size=10)\n",
    "        ax[i].set_xlabel(r\"$x_0$\", size=10)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plot the function of the first layer\n",
    "plt.close(\"all\")\n",
    "plt_layer_relu(\n",
    "    X_train,\n",
    "    y_train.reshape(\n",
    "        -1,\n",
    "    ),\n",
    "    W1,\n",
    "    b1,\n",
    "    classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340b948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather the trained parameters from the output layer\n",
    "W2, b2 = model.get_layer(\"L2\").get_weights()\n",
    "# create the 'new features', the training examples after L1 transformation\n",
    "X_L2 = np.maximum(0, (X_train @ W1 + b1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019d8eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_output_layer_linear(X, y, W, b, classes, x0_rng=None, x1_rng=None):\n",
    "    y = y.reshape(\n",
    "        -1,\n",
    "    )\n",
    "    nunits = W.shape[1]\n",
    "    # 1. Decide on a fixed number of columns (e.g., 2 or 3)\n",
    "    ncols = 2\n",
    "    # 2. Use math.ceil to ensure we have enough rows for all units\n",
    "    nrows = math.ceil(nunits / ncols)\n",
    "\n",
    "    # 3. Create the subplots\n",
    "    fig, ax = plt.subplots(nrows, ncols, figsize=(ncols * 3.5, nrows * 2.5))\n",
    "    # 4. Flatten the axes for easy iteration\n",
    "    # Note: if nrows*ncols > nunits, we'll have empty plots.\n",
    "    # We turn them off later.\n",
    "    axes = ax.flatten() if nunits > 1 else [ax]\n",
    "    hide_header_footer_toolbar(fig.canvas)\n",
    "    for i, axi in enumerate(ax.flat):\n",
    "        layer_fn = lambda x: x @ W[:, i] + b[i]\n",
    "        plt_prob_z(axi, layer_fn, x0_rng=x0_rng, x1_rng=x1_rng)\n",
    "        plt_mc_data(axi, X, y, classes, cmap=\"tab10\", legend=True, size=50, m=\"o\")\n",
    "        axi.set_xlabel(r\"$a^{[1]}_0$\", size=9)\n",
    "        axi.set_ylabel(r\"$a^{[1]}_1$\", size=9)\n",
    "        axi.set_xlim(x0_rng)\n",
    "        axi.set_ylim(x1_rng)\n",
    "        axi.set_title(f\"Linear output unit {i}\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plt_output_layer_linear(\n",
    "    X_L2,\n",
    "    y_train,\n",
    "    W2,\n",
    "    b2,\n",
    "    classes,\n",
    "    x0_rng=(-0.25, np.max(X_L2[:, 0])),\n",
    "    x1_rng=(-0.25, np.max(X_L2[:, 1])),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-specialization-playground-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
