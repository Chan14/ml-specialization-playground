{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bea00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "# custom functions being developed interactively\n",
    "%aimport utils_practice_version\n",
    "import utils_practice_version as utils\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004725f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 - Fixing high bias.\n",
    "# Technique 1 - Get polynomial features\n",
    "x_train, y_train, x_cv, y_cv, x_test, y_test = utils.prepare_dataset(\n",
    "    \"data/c2w3_lab2_data1.csv\"\n",
    ")\n",
    "print(f\"the shape of the training set (input) is: {x_train.shape}\")\n",
    "print(f\"the shape of the training set (target) is: {y_train.shape}\\n\")\n",
    "print(f\"the shape of the cross validation set (input) is: {x_cv.shape}\")\n",
    "print(f\"the shape of the cross validation set (target) is: {y_cv.shape}\\n\")\n",
    "\n",
    "# Preview the first 5 rows\n",
    "print(f\"first 5 rows of the training inputs (1 feature):\\n {x_train[:5]}\\n\")\n",
    "\n",
    "# Instantiate the regression model class\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train and plot polynomial regression models\n",
    "utils.train_plot_poly(model, x_train, y_train, x_cv, y_cv, max_degree=10, baseline=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72048235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and plot polynomial regression models. Baseline bias is defined lower.\n",
    "utils.train_plot_poly(model, x_train, y_train, x_cv, y_cv, max_degree=10, baseline=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01666f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Technique 2 - Add features\n",
    "x_train, y_train, x_cv, y_cv, x_test, y_test = utils.prepare_dataset(\n",
    "    \"data/c2w3_lab2_data2.csv\"\n",
    ")\n",
    "\n",
    "print(f\"the shape of the training set (input) is: {x_train.shape}\")\n",
    "print(f\"the shape of the training set (target) is: {y_train.shape}\\n\")\n",
    "print(f\"the shape of the cross validation set (input) is: {x_cv.shape}\")\n",
    "print(f\"the shape of the cross validation set (target) is: {y_cv.shape}\\n\")\n",
    "\n",
    "# Preview the first 5 rows\n",
    "print(f\"first 5 rows of the training inputs (2 features):\\n {x_train[:5]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd607812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model class\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train and plot polynomial regression models. Dataset used has two features.\n",
    "utils.train_plot_poly(model, x_train, y_train, x_cv, y_cv, max_degree=7, baseline=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dce918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Technique 3 - Decrease lambda, the regularization parameter\n",
    "# Define lambdas to plot\n",
    "reg_params = [10, 5, 2, 1, 0.5, 0.2, 0.1, 0.08, 0.06]\n",
    "\n",
    "# Define degree of polynomial and train for each value of lambda\n",
    "utils.train_plot_reg_params(\n",
    "    reg_params, x_train, y_train, x_cv, y_cv, degree=4, baseline=250\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fa7951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 - Fixing high variance\n",
    "# Technique 1 - Increase lambda, the regularization term.\n",
    "# Define lambdas to plot\n",
    "reg_params = [0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1]\n",
    "\n",
    "# Define degree of polynomial and train for each value of lambda\n",
    "utils.train_plot_reg_params(\n",
    "    reg_params, x_train, y_train, x_cv, y_cv, degree=4, baseline=250\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b87a375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Technique 2 - Try smaller sets of features\n",
    "# Prepare dataset with randomID feature\n",
    "# To illustrate how removing features can improve performance, you will do polynomial regression for 2 datasets: the same data you used above (2 features) and another with a random ID column (3 features). You can preview these using the cell below. Notice that 2 columns are identical and a 3rd one is added to include random numbers.\n",
    "x_train, y_train, x_cv, y_cv, x_test, y_test = utils.prepare_dataset(\n",
    "    \"data/c2w3_lab2_data2.csv\"\n",
    ")\n",
    "\n",
    "# Preview the first 5 rows\n",
    "print(f\"first 5 rows of the training set with 2 features:\\n {x_train[:5]}\\n\")\n",
    "\n",
    "# Prepare dataset with randomID feature\n",
    "x_train, y_train, x_cv, y_cv, x_test, y_test = utils.prepare_dataset(\n",
    "    \"data/c2w3_lab2_data3.csv\"\n",
    ")\n",
    "\n",
    "# Preview the first 5 rows\n",
    "print(\n",
    "    f\"first 5 rows of the training set with 3 features (1st column is a random ID):\\n {x_train[:5]}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef77816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Define properties of the 2 datasets\n",
    "file1 = {\n",
    "    \"filename\": \"data/c2w3_lab2_data3.csv\",\n",
    "    \"label\": \"3 features\",\n",
    "    \"linestyle\": \"dotted\",\n",
    "}\n",
    "file2 = {\n",
    "    \"filename\": \"data/c2w3_lab2_data2.csv\",\n",
    "    \"label\": \"2 features\",\n",
    "    \"linestyle\": \"solid\",\n",
    "}\n",
    "files = [file1, file2]\n",
    "\n",
    "# Train and plot for each dataset\n",
    "utils.train_plot_diff_datasets(model, files, max_degree=4, baseline=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6ba136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Technique 3 - Get more training examples\n",
    "# Lastly, you can try to minimize the cross validation error by getting more examples. In the cell below, you will train a 4th degree polynomial model then plot the learning curve of your model to see how the errors behave when you get more examples.\n",
    "# Prepare the dataset\n",
    "x_train, y_train, x_cv, y_cv, x_test, y_test = utils.prepare_dataset(\n",
    "    \"data/c2w3_lab2_data4.csv\"\n",
    ")\n",
    "\n",
    "print(f\"the shape of the entire training set (input) is: {x_train.shape}\")\n",
    "print(f\"the shape of the entire training set (target) is: {y_train.shape}\\n\")\n",
    "print(f\"the shape of the entire cross validation set (input) is: {x_cv.shape}\")\n",
    "print(f\"the shape of the entire cross validation set (target) is: {y_cv.shape}\\n\")\n",
    "\n",
    "# Instantiate the model class\n",
    "model = LinearRegression()\n",
    "\n",
    "# Define the degree of polynomial and train the model using subsets of the dataset.\n",
    "utils.train_plot_learning_curve(\n",
    "    model, x_train, y_train, x_cv, y_cv, degree=4, baseline=250\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-specialization-playground-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
